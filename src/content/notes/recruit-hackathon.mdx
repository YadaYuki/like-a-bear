---
noteId: "recruit-hackathon"
title: "リクルートのデータサイエンスハッカソンに行ってきた。"
description: ""
category: "other"
emoji: "👋"
tags: ["machine learning", "hackathon", "data science"]
pubDate: "2021-06-07"
---

# はじめに

どうも、矢田宙生です。
４月に研究室に配属され、現在、慣れない英語論文とゼミ発表とやらと格闘中です。
５月末、リクルートのデータサイエンスハッカソンに参加してきました。本記事はそのまとめです。

# 本記事の概要

本記事の概要は以下の通りです。

- リクルートの「データサイエンスハッカソン」に参加してきた。
- CRISP-DM というデータサイエンスのデータ分析プロセスのフレームワークに従ったデータ分析を 4 人グループで行う。
- Kaggle のように「事前に指定された評価関数に基づき算出された精度を競う」のではなく、ビジネス的価値を事前に話し合い、「なぜその評価指標・手法の設定をしたのか？という部分も含めて評価対象」というデータサイエンスのコンペとしては少し変わった形式。

# ハッカソンに参加する理由と選考フロー

インターンの内容について触れていく前に参加した理由と選考フローについてです。

まず、参加した理由についてですが、実践的なデータサイエンススキルを伸ばしていくきっかけが欲しかった、これに尽きます。

僕は今でこそ、アプリ・ソフトウェア開発中心ですが、プログラミングを始めた当初は、むしろ「データサイエンス・機械学習」に強い興味がありました。そのため、大学２年生の頃、以下のことに取り組んでいました。

- Coursera の ML コースを終了し基礎知識を身につける
- Kaggle に参加する。

しかし、以下の理由からモチベーションを持続させることができず、挫折してしまいました。

- オライリー・ジャパン発行の本や Kaggle のカーネルに書いていあることを理解することができなかった。
- 自分で考えたことを実装できるほどの開発スキルが当時はなかった。
- 機械学習自体あまり詳しくなかったので、「自分の考えた特徴量や新しいアルゴリズムを試し、精度を上げる」というデータサイエンス において一番楽しいであろうプロセスを体験することができなかった。
- 目標設定が無謀すぎた。（「今初心者だけど 3 ヶ月後には Kaggle expert なっちゃる！」と思っていた。）

といった理由からモチベーションを持続させることがができず、挫折してしまいました。

挫折するとほぼ同時にアプリ開発を始め、そっちが楽しくなってしまい、今に至る、という感じです。

しかし、今年(大学 4 年)の春からビッグデータや Web マイニングを専門とする研究室に入り、自分の中での機械学習熱が再燃していました。

「データサイエンス・機械学習の勉強がまたやりたいなぁ・・・」そんなふうにぼんやりと思っていたところ、本インターンの募集を見つけた、というのが応募したきっかけです。

次に選考フローについてです。選考は、エントリーシートのみ。今までの開発経験とプログラミング言語の経験に関する質問でした。データサイエンス系の経験があまりなかったため若干不安でしたが、なんとか合格することができました。

## 2. インターンの内容

さて、いよいよインターン当日です！

やったことは「Air レジ」という 0 円で簡単に使える POS レジ青売りに関連する回帰タスクを CRISP-DM というサイクルに基づいて解いていきました。

ここで CRISP-DM に関する説明です。

CRISP-DM はデータ分析プロセス・手法の一つで、以下のようなステップを繰り返すことを通してデータ分析を進めていきます。

1. 「解決しようとしている課題は何か？」「課題の解決を通してどのような結果を得ることがベストなのか？」に関する考察。
2. データ理解: 収集したデータの傾向を把握する。特徴量同士の相関や特徴量の分布、自己相関などからデータに関する知見を得る。
3. データ準備: データの整形。いわゆる特徴量エンジニアリング。
4. モデリング: 機械学習アルゴリズムの選定やパラメーターのチューニング等。
5. 評価: 評価関数の選定と評価。6.デプロイ 1〜5 のステップを経て得られた機械学習モデルを本番に公開する。

この CRISP-DM という手法なのですが、僕が取り組んだ経験のあるデータサイエンス タスクとは根本的に異なります。

僕が Kaggle を通して、今までやってきたデータサイエンス タスクは「データ」と「精度を評価するための指標」が与えられた上で、数値的指標を競うだけのある意味シンプルでわかりやすいものでした。

しかし CRISP-DM は、「何がこのデータ分析 タスクのゴールであるのか？を明確に定義する」というところもそのプロセス内に含まれています。

そしてその部分は、その後のデータ分析の意思決定全てに影響を与えるので、ある意味では最も重要なプロセスです。

今回のハッカソンではそこも評価対象であったため、

- あるチームは予測精度を重視したり、
- あるチームは多少予測精度を犠牲にしても、上方予測になるようにパラメータをチューニングしていたり、

と、最終的なアウトプットにチームの個性が非常に現れており、とても面白かったです。

CRISP-DM はこのハッカソンで初めて知った考え方でした。実ビジネス的で非常に参考になるなぁ、と思いました。

以上がハッカソンのざっくりとした内容です

### 3. 振り返り・反省点

最後に振り返りと反省点です。 良かった点としては次の 3 点が挙げられます。

- チームを二つに分割して作業することによって、効率よく作業を進められた点。
- 普段からデータサイエンスをメインで取り組んでいる人と機械学習周辺のやりとりがスムーズにできた点。
- 実装する作業が迅速にできた点。

また、ビジネス理解の重要性やアルゴリズムの理解についても、今後改めて学ぶことを意識していきたいです。ハッカソンでの反省点を踏まえて、今後の自分自身のスキルアップに繋げたいと思います。

そして、今回のハッカソンでチームメンバーと共に取り組んだ成果や知見を、今後のプロジェクトや業務に活かしていきたいと思います。最後に、このハッカソンに参加することができて、大変貴重な経験をすることができました。今後もデータサイエンス分野での活躍を目指して、スキルアップに努めていきたいと思います。

機械学習関連の分野の論文を書いた経験のある大学院生やインターン等で機械学習系の実装をゴリゴリやっている人たちの中で、自分のスキルが通用するか？という点については特に不安でしたが、

- データサイエンスのフローや主要なライブラリの利用等を Kaggle やオンラインコースで経験していたこと。
- ソフトウェアエンジニアとしての実装力。

これらが当日は非常に役に立ったなぁ、と思います。

次に反省点です。

- ビジネス理解の重要性を理解しておらず、１回目のビジネス理解が若干おざなりであった。
- Prophet や LightGBM の内部構造を理解していなかったため、パラメータのチューニングやそれらのアルゴリズムの特性を考慮した特徴量エンジニアリングを積極的に取り組めなかった。

特に二点目のアルゴリズムに対する理解は非常に重要だと思います。

Web 開発にも言えることですが、現代は便利なライブラリが多数存在しており、それらを呼び出すだけで、それなりのアウトプットを出すことができてしまいます。

しかしそれでは、ライブラリを使っているだけのなんちゃってデータサイエンティストなので、背景にあるアルゴリズムをきちんと理解することがやはり非常に重要だなと思いました。

その方が応用ができるのはもちろんですが、「なぜ高い精度が出たのか？」「なぜこのような出力をするのか？」という部分がわかるようになるので、いろいろ工夫するようになり、作業自体も面白くなるはずです。  なので

- 機械学習の応用力を上げるために、機械学習を組み込んだプロダクトを実装する。
- 機械学習アルゴリズムをライブラリに頼らず、スクラッチ実装する。
- 統計検定などを活用して、数学的な素養を身につけ、そこで得た知見もアウトプットする。

というのを自分の今のスキルからみて少し負荷がかかる、くらいの感じで進めていくのが具体的なアクションとして良いかなぁ、と思いました。

# 4. まとめ

最後にまとめです。 データサイエンス ハッカソンに参加するのは初めてでしたが、実際に活躍されているデータサイエンティストとの交流や CRISP-DM というデータ分析プロセスの実践などは非常に勉強になりました。

機械学習のスキル・知識をもっと伸ばし、「機械学習・データサイエンス のわかるエンジニア」もしくは「エンジニアリングのわかデデータサイエンティスト」を目指して今後も精進していきたいと思います。
